{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e52df4-501e-4920-95e9-6e52ac85dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np  # linear alg\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "#from keras.optimizers import RMSprop\n",
    "#from tensorflow.keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ec5161-bdf2-4d8d-a4a0-c7b3c2b8f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs = 5\n",
    "random.seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db5ed46-0135-4623-94f9-351ccc738461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "941d1eb1-d202-42ea-b9bf-ed0070416a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0648d55-3bb4-4ffa-be1d-4dbfc782010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "      uses y_true as Y and y_pred as the Euclidean distance between dissimilar points\n",
    "    '''\n",
    "    print(\"yes, contrastive\")\n",
    "    margin = 1\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    sqaure_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * sqaure_pred + (1 - y_true) * margin_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cd7743c-69dc-4842-9467-66c09af03c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    input = Input(shape=input_shape)\n",
    "    x = input\n",
    "    \n",
    "    x = Conv2D(32, kernel_size=3, activation='relu', input_shape=input_shape,padding='same')(x)\n",
    "    x= tf.keras.layers.AveragePooling2D()(x)\n",
    "    x = Conv2D(32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x= tf.keras.layers.AveragePooling2D()(x)\n",
    "    x = Conv2D(32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x= tf.keras.layers.AveragePooling2D()(x)\n",
    "    x = Flatten()(x) \n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    \n",
    "    x = Lambda(lambda x: K.l2_normalize(x, axis=1))(x) \n",
    "    return Model(input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ee15e80-c3b4-48c6-b479-62b486b53818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f307f726-235f-4eb1-82de-85504f78e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b945796c-2131-4e65-b88d-46f3a14eb174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormed(this_array, this_min = 0, this_max = 255, set_to_int = True):\n",
    "    new_var = this_array.copy()\n",
    "    rat = (this_max - this_min)/(new_var.max() - new_var.min())\n",
    "    new_var = new_var * rat\n",
    "    new_var -= new_var.min()\n",
    "    new_var += this_min\n",
    "    if set_to_int:\n",
    "        return new_var.astype('uint8')\n",
    "    return new_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0ba6f3c-67e4-4c90-9adc-60355c47e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv('/Users/amalalmansour/Desktop/New_Images/Malignancy/train.csv')\n",
    "train = pd.read_csv('/Users/amalalmansour/Desktop/New_Images/Spiculation/train.csv')\n",
    "#test = pd.read_csv('/Users/amalalmansour/Desktop/New_Images/Malignancy/test.csv')\n",
    "test = pd.read_csv('/Users/amalalmansour/Desktop/New_Images/Spiculation/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d77fc2e-407d-4c20-93d5-9374a6be1ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodIds = train['noduleID']\n",
    "test_nodIds = test['noduleID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e20870e-e6ba-4b7e-bcd3-1e82b5243f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodIds = np.array(train_nodIds)\n",
    "test_nodIds = np.array(test_nodIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fc7eea6-832e-433e-b364-3f1d4fd7806a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amalalmansour/Desktop/images_1332\n",
      ".DS_Store\n",
      "Malignancy_2\n",
      "Malignancy_5\n",
      "Malignancy_4\n",
      "Malignancy_3\n",
      "Malignancy_1\n"
     ]
    }
   ],
   "source": [
    "image_folder = '/Users/amalalmansour/Desktop/images_1332'\n",
    "train_images = []\n",
    "test_images = []\n",
    "train_noduleId = []\n",
    "test_noduleId = []\n",
    "print(image_folder)\n",
    "\n",
    "for dir1 in os.listdir(image_folder):\n",
    "    print(dir1)\n",
    "    if not dir1.startswith('.'):\n",
    "        for file in os.listdir(os.path.join(image_folder, dir1)):\n",
    "            #print(file)\n",
    "            noduleID = file.split('.')[0]\n",
    "            if not file.startswith('.'):\n",
    "                noduleID = int(noduleID)\n",
    "                if noduleID in train_nodIds:\n",
    "                    train_noduleId.append(noduleID)\n",
    "                    temp_image = np.loadtxt(os.path.join(image_folder, dir1,file))\n",
    "                    temp_image = getNormed(temp_image)\n",
    "                    #enlarged_img = getSamePadding(temp_image)\n",
    "                    train_images.append(temp_image)\n",
    "            \n",
    "                if noduleID in test_nodIds:\n",
    "                    test_noduleId.append(noduleID)\n",
    "                    temp_image = np.loadtxt(os.path.join(image_folder, dir1,file))\n",
    "                    temp_image = getNormed(temp_image)\n",
    "                    #enlarged_img = getSamePadding(temp_image)\n",
    "                    test_images.append(temp_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8daa074c-b844-4e89-8090-0f9bc28cbfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     noduleID\n",
      "0        2412\n",
      "1        2374\n",
      "2         471\n",
      "3        1907\n",
      "4        1496\n",
      "..        ...\n",
      "577       440\n",
      "578       657\n",
      "579      2609\n",
      "580       904\n",
      "581       290\n",
      "\n",
      "[582 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "tr_df = pd.DataFrame(train_noduleId,columns =['noduleID'])\n",
    "print(tr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3d8bb53-5652-4a48-a311-bea52a0d1f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     noduleID\n",
      "0        1252\n",
      "1        1497\n",
      "2        2564\n",
      "3        2558\n",
      "4        1958\n",
      "..        ...\n",
      "140      2421\n",
      "141      1869\n",
      "142      1698\n",
      "143       643\n",
      "144      2594\n",
      "\n",
      "[145 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "te_df = pd.DataFrame(test_noduleId,columns =['noduleID'])\n",
    "print(te_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74b9a6e7-8a97-4339-991c-d590ac5baf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noduleID</th>\n",
       "      <th>InstanceID</th>\n",
       "      <th>Binary_Rating_Mal</th>\n",
       "      <th>Binary_Rating_Spic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>118</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>134</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>2655</td>\n",
       "      <td>40771</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>2657</td>\n",
       "      <td>40780</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>2656</td>\n",
       "      <td>40794</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>2658</td>\n",
       "      <td>40801</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>2660</td>\n",
       "      <td>40860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1332 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      noduleID  InstanceID  Binary_Rating_Mal  Binary_Rating_Spic\n",
       "0            1           4                  1                   3\n",
       "1            5         118                  3                   0\n",
       "2            3         134                  3                   3\n",
       "3            4         143                  3                   3\n",
       "4            6         175                  0                   0\n",
       "...        ...         ...                ...                 ...\n",
       "1327      2655       40771                  3                   0\n",
       "1328      2657       40780                  1                   3\n",
       "1329      2656       40794                  1                   3\n",
       "1330      2658       40801                  3                   3\n",
       "1331      2660       40860                  0                   0\n",
       "\n",
       "[1332 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/amalalmansour/Desktop/New_Images/LIDC_LabelANDRating.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1b7bfb6-8259-4a34-8bdb-eeb57674ad51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noduleID</th>\n",
       "      <th>InstanceID</th>\n",
       "      <th>Binary_Rating_Mal</th>\n",
       "      <th>Binary_Rating_Spic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2412</td>\n",
       "      <td>36785</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2374</td>\n",
       "      <td>36253</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>471</td>\n",
       "      <td>6853</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1907</td>\n",
       "      <td>29039</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1496</td>\n",
       "      <td>22427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>440</td>\n",
       "      <td>6517</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>657</td>\n",
       "      <td>9498</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>2609</td>\n",
       "      <td>39936</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>904</td>\n",
       "      <td>13301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>290</td>\n",
       "      <td>4296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>582 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     noduleID  InstanceID  Binary_Rating_Mal  Binary_Rating_Spic\n",
       "0        2412       36785                  0                   0\n",
       "1        2374       36253                  3                   0\n",
       "2         471        6853                  3                   0\n",
       "3        1907       29039                  3                   0\n",
       "4        1496       22427                  0                   0\n",
       "..        ...         ...                ...                 ...\n",
       "577       440        6517                  0                   0\n",
       "578       657        9498                  3                   0\n",
       "579      2609       39936                  0                   0\n",
       "580       904       13301                  0                   0\n",
       "581       290        4296                  0                   0\n",
       "\n",
       "[582 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_slices = pd.merge(tr_df, df)\n",
    "display(train_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a8a0cb0-af68-499b-a695-2a6f9e89ff1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noduleID</th>\n",
       "      <th>InstanceID</th>\n",
       "      <th>Binary_Rating_Mal</th>\n",
       "      <th>Binary_Rating_Spic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1252</td>\n",
       "      <td>18823</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1497</td>\n",
       "      <td>22434</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2564</td>\n",
       "      <td>39328</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2558</td>\n",
       "      <td>39203</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1958</td>\n",
       "      <td>29602</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2421</td>\n",
       "      <td>36955</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1869</td>\n",
       "      <td>28376</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1698</td>\n",
       "      <td>25416</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>643</td>\n",
       "      <td>9251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2594</td>\n",
       "      <td>39806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     noduleID  InstanceID  Binary_Rating_Mal  Binary_Rating_Spic\n",
       "0        1252       18823                  3                   0\n",
       "1        1497       22434                  3                   0\n",
       "2        2564       39328                  0                   1\n",
       "3        2558       39203                  3                   0\n",
       "4        1958       29602                  0                   0\n",
       "..        ...         ...                ...                 ...\n",
       "140      2421       36955                  0                   0\n",
       "141      1869       28376                  0                   0\n",
       "142      1698       25416                  0                   0\n",
       "143       643        9251                  0                   0\n",
       "144      2594       39806                  0                   0\n",
       "\n",
       "[145 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_slices = pd.merge(te_df, df)\n",
    "display(test_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89e0c1fa-0b3a-4a89-925e-8ff55dc33d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ids = train_slices[\"Binary_Rating_Spic\"]\n",
    "train_labels = train_slices[\"Binary_Rating_Spic\"]\n",
    "train_ids = train_slices['InstanceID']\n",
    "#test_ids = test_slices[\"Binary_Rating_Spic\"]\n",
    "test_labels = test_slices[\"Binary_Rating_Spic\"]\n",
    "test_ids = test_slices['InstanceID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d13ee313-8bfd-4d5b-adb2-587ea6b27df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582\n",
      "145\n"
     ]
    }
   ],
   "source": [
    "train_images = np.array(train_images)\n",
    "print(len(train_images))\n",
    "test_images = np.array(test_images)\n",
    "print(len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0615c8f-c0f8-4eba-ba95-b2330f96f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data so the pixel vectors turn into arrays, and so the instance id's are also arrays\n",
    "train_images = train_images.reshape(train_images.shape[0],71,71,1)  \n",
    "train_ids = np.array(train_ids)\n",
    "train_labels = np.array(train_labels)\n",
    "test_images = test_images.reshape(test_images.shape[0], 71, 71,1)\n",
    "test_ids = np.array(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc432407-0d1d-44c4-8733-5a22e785a485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12376, 2, 71, 71)\n",
      "(12376, 2, 71, 71, 1)\n",
      "(12376,)\n"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "pickle_in = open(\"/Users/amalalmansour/Desktop/New_Images/Spiculation/Siamese/pickle/TestPairs1.pickle\", \"rb\")\n",
    "testPixel = pickle.load(pickle_in)\n",
    "testPixel = np.array(testPixel)\n",
    "print(testPixel.shape)\n",
    "te_pairs = testPixel.reshape(testPixel.shape[0],2,71,71,1)\n",
    "print(te_pairs.shape)\n",
    "\n",
    "#test labels\n",
    "pickle_in = open(\"/Users/amalalmansour/Desktop/New_Images/Spiculation/Siamese/pickle/TestLabels1.pickle\", \"rb\")\n",
    "te_y = pickle.load(pickle_in)\n",
    "te_y = np.array(te_y)\n",
    "print(te_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c854bcf-1c81-46cf-b838-2ba554b32234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain = pd.read_csv(filepath + \\'Train_Pixels.csv\\')\\n#train = train.drop([\\'noduleID\\', \\'Dataset\\',\\'Category\\'],  axis=1)\\n\\ntest = pd.read_csv(filepath + \\'Test_Pixels.csv\\')\\n#test = test.drop([\\'noduleID\\', \\'Dataset\\',\\'Category\\'],  axis=1)\\n\\ntrain_labels = train[\"Binary Rating\"]\\n\\ntrain_ids = train[\\'InstanceID\\']\\ntrain_images = train.drop([\\'InstanceID\\', \\'Binary Rating\\'],  axis=1)\\n\\ntest_ids = test[\\'InstanceID\\']\\ntest_images = test.drop([\\'InstanceID\\', \\'Binary Rating\\'], axis=1)\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train = pd.read_csv(filepath + 'Train_Pixels.csv')\n",
    "#train = train.drop(['noduleID', 'Dataset','Category'],  axis=1)\n",
    "\n",
    "test = pd.read_csv(filepath + 'Test_Pixels.csv')\n",
    "#test = test.drop(['noduleID', 'Dataset','Category'],  axis=1)\n",
    "\n",
    "train_labels = train[\"Binary Rating\"]\n",
    "\n",
    "train_ids = train['InstanceID']\n",
    "train_images = train.drop(['InstanceID', 'Binary Rating'],  axis=1)\n",
    "\n",
    "test_ids = test['InstanceID']\n",
    "test_images = test.drop(['InstanceID', 'Binary Rating'], axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2c37a7e-1bb0-4529-aa3e-c5f7fa3135d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = []\n",
    "train_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a3c4d92-b55e-4105-a7a1-1f0d8c50dbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 71, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d583c0d-36b0-4f6e-af61-70ce60fc9a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape ==== (71, 71, 1)\n"
     ]
    }
   ],
   "source": [
    "input_shape = train_images.shape[1:]\n",
    "print('input shape ====', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a933c11-3449-4e6a-8e4f-6f29a5de8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network definition\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40c741d9-75e6-47af-942e-bc9e2668568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "because we re-use the same instance `base_network`,\n",
    "the weights of the network\n",
    "will be shared across the two branches \n",
    "'''\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c225b319-50c2-4828-8b98-b9be541b81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac94deed-25e0-4598-8ad7-3bf18169489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_a, input_b], distance)  #think we are shaping our model \n",
    "model.compile(loss=contrastive_loss, optimizer='adam', metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2463b2a7-6c79-4c1e-ab49-2d0df9d751ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 71, 71, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 71, 71, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 512)          1067904     ['input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 1)            0           ['model[0][0]',                  \n",
      "                                                                  'model[1][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,067,904\n",
      "Trainable params: 1,067,904\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##### Import Trained Model #####\n",
    "#model = keras.models.load_model(\"/Users/amalalmansour/Downloads/REU_SCNN-main/LIDC/Amal_Agreement/Spiculation_slices/max_slices/pickle/my_model_original\" , compile = True, custom_objects={\"contrastive_loss\": contrastive_loss})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58f83fe0-4d62-4c49-ba45-950cf1368ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pairs...\n"
     ]
    }
   ],
   "source": [
    "filepath ='/Users/amalalmansour/Desktop/New_Images/Spiculation/Siamese/'\n",
    "print(\"loading pairs...\")\n",
    "path = filepath + 'pickle/'\n",
    "training_loss =[]\n",
    "test_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9da830d-e5c4-487b-adb8-2557f7a9f489",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in1 = open(path + \"TrainPairs1.pickle\", \"rb\")\n",
    "trainPixel1 = pickle.load(pickle_in1)\n",
    "trainPixel1 = np.asarray(trainPixel1)\n",
    "tr_pairs1 = trainPixel1.reshape(trainPixel1.shape[0],trainPixel1.shape[1],71,71,1)\n",
    "#train_pairs.append(tr_pairs1)\n",
    "\n",
    "pickle_in2 = open(path + \"TrainPairs2.pickle\", \"rb\")\n",
    "trainPixel2 = pickle.load(pickle_in2)\n",
    "trainPixel2 = np.asarray(trainPixel2)\n",
    "tr_pairs2 = trainPixel2.reshape(trainPixel2.shape[0],trainPixel2.shape[1],71,71,1)\n",
    "#train_pairs.append(tr_pairs2)\n",
    "\n",
    "pickle_in3 = open(path + \"TrainPairs3.pickle\", \"rb\")\n",
    "trainPixel3 = pickle.load(pickle_in3)\n",
    "trainPixel3 = np.asarray(trainPixel3)\n",
    "tr_pairs3 = trainPixel3.reshape(trainPixel3.shape[0],trainPixel3.shape[1],71,71,1)\n",
    "#train_pairs.append(tr_pairs3)\n",
    "\n",
    "pickle_in4 = open(path + \"TrainPairs4.pickle\", \"rb\")\n",
    "trainPixel4 = pickle.load(pickle_in4)\n",
    "trainPixel4 = np.asarray(trainPixel4)\n",
    "tr_pairs4 = trainPixel4.reshape(trainPixel4.shape[0],trainPixel4.shape[1],71,71,1)\n",
    "\n",
    "pickle_in5 = open(path + \"TrainPairs5.pickle\", \"rb\")\n",
    "trainPixel5 = pickle.load(pickle_in5)\n",
    "trainPixel5 = np.asarray(trainPixel5)\n",
    "tr_pairs5 = trainPixel5.reshape(trainPixel5.shape[0],trainPixel5.shape[1],71,71,1)\n",
    "\n",
    "# train labels:\n",
    "pickle_lb1 = open(path + \"TrainLabels1.pickle\", \"rb\")\n",
    "tr_y1 = pickle.load(pickle_lb1)\n",
    "tr_y1 = np.array(tr_y1)\n",
    "#train_y.append(tr_y1)\n",
    "\n",
    "# train labels:\n",
    "pickle_lb2 = open(path + \"TrainLabels2.pickle\", \"rb\")\n",
    "tr_y2 = pickle.load(pickle_lb2)\n",
    "tr_y2 = np.array(tr_y2)\n",
    "#train_y.append(tr_y2)\n",
    "\n",
    "# train labels:\n",
    "pickle_lb3 = open(path + \"TrainLabels3.pickle\", \"rb\")\n",
    "tr_y3 = pickle.load(pickle_lb3)\n",
    "tr_y3 = np.array(tr_y3)\n",
    "#train_y.append(tr_y3)\n",
    "\n",
    "# train labels:\n",
    "pickle_lb4 = open(path + \"TrainLabels4.pickle\", \"rb\")\n",
    "tr_y4 = pickle.load(pickle_lb4)\n",
    "tr_y4 = np.array(tr_y4)\n",
    "#train_y.append(tr_y4)\n",
    "\n",
    "# train labels:\n",
    "pickle_lb5 = open(path + \"TrainLabels5.pickle\", \"rb\")\n",
    "tr_y5 = pickle.load(pickle_lb5)\n",
    "tr_y5 = np.array(tr_y5)\n",
    "#train_y.append(tr_y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54229a53-8c34-477b-b3b7-e30cc9ee61d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No weights yet...\n",
      "yes, contrastive\n",
      "yes, contrastive\n",
      "129/313 [===========>..................] - ETA: 7s - loss: 0.2246 - accuracy: 0.6299"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-7b13617f9adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No weights yet...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     history = model.fit([tr_pairs1[:, 0], tr_pairs1[:, 1]], tr_y1,\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# epoch = 5\n",
    "for epoch in range(50):\n",
    "    \n",
    "    # Load weights:\n",
    "    isExist = os.path.exists(path + \"Saved_Weights\") \n",
    "    #print(isExist)\n",
    "    if isExist == True:\n",
    "        print(\"Loading weights...\")\n",
    "        model.load_weights(path + \"Saved_Weights/weights.ckpt\")\n",
    "    else:\n",
    "        print(\"No weights yet...\")\n",
    "\n",
    "    history = model.fit([tr_pairs1[:, 0], tr_pairs1[:, 1]], tr_y1,\n",
    "      batch_size=128,\n",
    "      epochs=epoch+1,\n",
    "      initial_epoch = epoch,\n",
    "      shuffle=True,\n",
    "      validation_data=((te_pairs[:, 0], te_pairs[:, 1]), te_y))\n",
    "    training_loss += history.history['loss']\n",
    "    test_loss += history.history['val_loss']\n",
    "    print(f\"{epoch}) Training for {epoch+1} epoch is complete.\")\n",
    "\n",
    "    history = model.fit([tr_pairs2[:, 0], tr_pairs2[:, 1]], tr_y2,\n",
    "      batch_size=128,\n",
    "      epochs=epoch+1,\n",
    "      initial_epoch = epoch,\n",
    "      shuffle=True,\n",
    "      validation_data=((te_pairs[:, 0], te_pairs[:, 1]), te_y))\n",
    "    training_loss += history.history['loss']\n",
    "    test_loss += history.history['val_loss']\n",
    "    print(f\"{epoch}) Training for {epoch+1} epoch is complete.\")\n",
    "\n",
    "    history = model.fit([tr_pairs3[:, 0], tr_pairs3[:, 1]], tr_y3,\n",
    "      batch_size=128,\n",
    "      epochs=epoch+1,\n",
    "      initial_epoch = epoch,\n",
    "      shuffle=True,\n",
    "      validation_data=((te_pairs[:, 0], te_pairs[:, 1]), te_y))\n",
    "    training_loss += history.history['loss']\n",
    "    test_loss += history.history['val_loss']\n",
    "    print(f\"{epoch}) Training for {epoch+1} epoch is complete.\")\n",
    "    \n",
    "    history = model.fit([tr_pairs4[:, 0], tr_pairs4[:, 1]], tr_y4,\n",
    "      batch_size=128,\n",
    "      epochs=epoch+1,\n",
    "      initial_epoch = epoch,\n",
    "      shuffle=True,\n",
    "      validation_data=((te_pairs[:, 0], te_pairs[:, 1]), te_y))\n",
    "    training_loss += history.history['loss']\n",
    "    test_loss += history.history['val_loss']\n",
    "    print(f\"{epoch}) Training for {epoch+1} epoch is complete.\")\n",
    "    \n",
    "    history = model.fit([tr_pairs5[:, 0], tr_pairs5[:, 1]], tr_y5,\n",
    "      batch_size=128,\n",
    "      epochs=epoch+1,\n",
    "      initial_epoch = epoch,\n",
    "      shuffle=True,\n",
    "      validation_data=((te_pairs[:, 0], te_pairs[:, 1]), te_y))\n",
    "    training_loss += history.history['loss']\n",
    "    test_loss += history.history['val_loss']\n",
    "    print(f\"{epoch}) Training for {epoch+1} epoch is complete.\")\n",
    "        \n",
    "    #base_network.save(path + \"my_model\")\n",
    "    #model.save_weights(path + \"Saved_Weights/weights.ckpt\")\n",
    "    print(\"Saving weights...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260add3-4e8b-4217-abdf-1376c4c08f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fc18a8-701f-4d16-a7a5-aa1423e71436",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"/Users/amalalmansour/Desktop/New_Images/Spiculation/Siamese/pickle/my_model\" , compile = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b960e5c0-97ab-4937-a8bb-a2fd37afadfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0089af8b-de73-49a7-a969-625d0c4c6e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_epoch_loss = []\n",
    "i = 0\n",
    "for _ in range(50):\n",
    "    loss = 0.\n",
    "    for _ in range(5):\n",
    "        loss += training_loss[i]\n",
    "        i+=1\n",
    "    tr_epoch_loss.append(float(loss)/5)\n",
    "len(tr_epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5422a53-6a9a-47f3-9fd4-42b145286eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_epoch_loss = []\n",
    "i = 0\n",
    "for _ in range(50):\n",
    "    loss = 0.\n",
    "    for _ in range(5):\n",
    "        loss += test_loss[i]\n",
    "        i+=1\n",
    "    t_epoch_loss.append(float(loss)/5)\n",
    "len(t_epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef478b53-05af-42c5-a5e7-d4f6684d7d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_count = range(1,len(tr_epoch_loss)+1)\n",
    "plt.plot(epoch_count, tr_epoch_loss)\n",
    "plt.plot(epoch_count, t_epoch_loss)\n",
    "plt.legend(['Training Loss','Testing Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27033ab8-d313-4bb7-8fa3-c15ebe686835",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_te_before = model.predict((te_pairs[:, 0], te_pairs[:, 1]))\n",
    "y_pred_te = (y_pred_te_before - y_pred_te_before.min()) / (y_pred_te_before.max() - y_pred_te_before.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0824a3e0-9d23-4e05-b19a-3280e49c4b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
